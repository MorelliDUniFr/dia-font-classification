{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "Second try, with a basic model"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "4ac20b28058858bd"
  },
  {
   "cell_type": "markdown",
   "source": [
    "Imports"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "705740ac830b5b02"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from torchvision import datasets, transforms\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "from torchvision import models\n",
    "from torch.utils.data import DataLoader\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from sklearn.preprocessing import label_binarize"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-18T17:18:01.078225Z",
     "start_time": "2024-03-18T17:18:01.069226Z"
    }
   },
   "id": "cd70965188811652",
   "execution_count": 21
  },
  {
   "cell_type": "markdown",
   "source": [
    "Choose a model"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "89723516c4abb2e6"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using model: resnet18\n"
     ]
    }
   ],
   "source": [
    "model_name = 'resnet18'\n",
    "print(f'Using model: {model_name}')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-18T17:18:01.900225Z",
     "start_time": "2024-03-18T17:18:01.887226Z"
    }
   },
   "id": "ef4e56728f9785b4",
   "execution_count": 22
  },
  {
   "cell_type": "markdown",
   "source": [
    "Load and prepare the dataset"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "b2dabad339631e94"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of images: 15000\n",
      "Number of batches: 165\n",
      "Number of training images: 10500\n",
      "Number of validation images: 2250\n",
      "Number of test images: 2250\n",
      "Class names: ['Algerian', 'Arial', 'Baskerville', 'Calibry', 'Calligraphy', 'Cambria', 'Comic Sans MS', 'Courier', 'Elephant', 'Fascinate', 'Georgia', 'Helvetica', 'Lucida Bright', 'Nasalization', 'Times New Roman']\n"
     ]
    }
   ],
   "source": [
    "image_height = 32\n",
    "image_width = 150\n",
    "batch_size = 64\n",
    "train_size_perc = 0.7\n",
    "\n",
    "# Define transformations for preprocessing\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((image_height, image_width)),  # Resize images to a fixed size\n",
    "    transforms.ToTensor(),                           # Convert images to tensors\n",
    "    transforms.Normalize(mean=[0.5, 0.5, 0.5],      # Normalize pixel values\n",
    "                         std=[0.5, 0.5, 0.5])])\n",
    "\n",
    "# Specify the path to your dataset\n",
    "data_dir = '../fonts'\n",
    "\n",
    "# Load the dataset using ImageFolder\n",
    "dataset = datasets.ImageFolder(root=data_dir, transform=transform)\n",
    "\n",
    "# Define the sizes of the training, validation, and test sets\n",
    "train_size = int(train_size_perc * len(dataset))  # 70% of the dataset for training\n",
    "val_size = int(((1.0 - train_size_perc)/2) * len(dataset))    # 15% for validation\n",
    "test_size = len(dataset) - train_size - val_size  # Remaining for test (15%)\n",
    "\n",
    "# Split the dataset into training, validation, and test sets\n",
    "train_dataset, val_dataset, test_dataset = torch.utils.data.random_split(\n",
    "    dataset, [train_size, val_size, test_size])\n",
    "\n",
    "# Create data loaders for training, validation, and test sets\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "val_loader = torch.utils.data.DataLoader(val_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "# Calculate the size of the dataset\n",
    "num_images = len(dataset)\n",
    "num_batches = len(train_loader)\n",
    "print(f'Number of images: {num_images}')\n",
    "print(f'Number of batches: {num_batches}')\n",
    "print(f'Number of training images: {len(train_dataset)}')\n",
    "print(f'Number of validation images: {len(val_dataset)}')\n",
    "print(f'Number of test images: {len(test_dataset)}')\n",
    "\n",
    "# Get the class names\n",
    "class_names = dataset.classes\n",
    "print(f'Class names: {class_names}')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-18T17:18:03.015948Z",
     "start_time": "2024-03-18T17:18:02.864574Z"
    }
   },
   "id": "1975b1b1848ca2ac",
   "execution_count": 23
  },
  {
   "cell_type": "markdown",
   "source": [
    "Load the model"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "bd836b0d47a237ba"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n"
     ]
    },
    {
     "ename": "AssertionError",
     "evalue": "Torch not compiled with CUDA enabled",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mAssertionError\u001B[0m                            Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[24], line 11\u001B[0m\n\u001B[0;32m      8\u001B[0m device \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mcpu\u001B[39m\u001B[38;5;124m'\u001B[39m\n\u001B[0;32m     10\u001B[0m \u001B[38;5;28mprint\u001B[39m(torch\u001B[38;5;241m.\u001B[39mcuda\u001B[38;5;241m.\u001B[39mis_available())\n\u001B[1;32m---> 11\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[43mtorch\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mrand\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m2\u001B[39;49m\u001B[43m,\u001B[49m\u001B[38;5;241;43m3\u001B[39;49m\u001B[43m)\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcuda\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m)\n\u001B[0;32m     13\u001B[0m \u001B[38;5;66;03m# Move model to the device (CPU or GPU)\u001B[39;00m\n\u001B[0;32m     14\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m platform \u001B[38;5;241m!=\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mwin32\u001B[39m\u001B[38;5;124m\"\u001B[39m:\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\torch\\cuda\\__init__.py:293\u001B[0m, in \u001B[0;36m_lazy_init\u001B[1;34m()\u001B[0m\n\u001B[0;32m    288\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mRuntimeError\u001B[39;00m(\n\u001B[0;32m    289\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mCannot re-initialize CUDA in forked subprocess. To use CUDA with \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    290\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mmultiprocessing, you must use the \u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mspawn\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m start method\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    291\u001B[0m     )\n\u001B[0;32m    292\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28mhasattr\u001B[39m(torch\u001B[38;5;241m.\u001B[39m_C, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m_cuda_getDeviceCount\u001B[39m\u001B[38;5;124m\"\u001B[39m):\n\u001B[1;32m--> 293\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mAssertionError\u001B[39;00m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mTorch not compiled with CUDA enabled\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[0;32m    294\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m _cudart \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m    295\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mAssertionError\u001B[39;00m(\n\u001B[0;32m    296\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mlibcudart functions unavailable. It looks like you have a broken build?\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    297\u001B[0m     )\n",
      "\u001B[1;31mAssertionError\u001B[0m: Torch not compiled with CUDA enabled"
     ]
    }
   ],
   "source": [
    "from sys import platform\n",
    "\n",
    "# Load the model\n",
    "model = models.__dict__[model_name](weights=None)\n",
    "num_ftrs = model.fc.in_features\n",
    "model.fc = torch.nn.Linear(num_ftrs, len(class_names))\n",
    "\n",
    "device = 'cpu'\n",
    "\n",
    "print(torch.cuda.is_available())\n",
    "print(torch.rand(2,3).cuda())\n",
    "\n",
    "# Move model to the device (CPU or GPU)\n",
    "if platform != \"win32\":\n",
    "    device = torch.device('mps' if torch.backends.mps.is_available() else 'cpu')\n",
    "# else:\n",
    "    # device = torch.device('gpu' if )\n",
    "model = model.to(device)\n",
    "print(f'Model moved to {device}')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-18T17:18:06.625967Z",
     "start_time": "2024-03-18T17:18:06.475968Z"
    }
   },
   "id": "8e9ad926f379fab5",
   "execution_count": 24
  },
  {
   "cell_type": "markdown",
   "source": [
    "Train the model"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "eebc3e7a492ce85"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "-------------------------------\n",
      "Training - Epoch [1/30], Step [10/165], Loss: 1.7582\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "KeyboardInterrupt\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Define the loss function\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "# Define the optimizer\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# Training loop\n",
    "num_epochs = 30\n",
    "best_val_loss = float('inf')\n",
    "\n",
    "# Set the model to training mode\n",
    "model.train()\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    print(f'Epoch {epoch + 1}\\n-------------------------------')\n",
    "    # Training phase\n",
    "    model.train()\n",
    "    train_loss = 0.0\n",
    "    for i, (inputs, labels) in enumerate(train_loader):\n",
    "        inputs = inputs.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        # Forward pass\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "        # Backward pass\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        train_loss += loss.item() * inputs.size(0)\n",
    "        \n",
    "        # Print training statistics\n",
    "        if (i + 1) % 10 == 0:\n",
    "            print(f'Training - Epoch [{epoch + 1}/{num_epochs}], Step [{i + 1}/{len(train_loader)}], Loss: {loss.item():.4f}')\n",
    "\n",
    "    # Calculate average training loss\n",
    "    train_loss /= len(train_loader.dataset)\n",
    "    \n",
    "    # Validation phase\n",
    "    model.eval()\n",
    "    val_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for i, (inputs, labels) in enumerate(val_loader):\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            # Forward pass\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "\n",
    "            val_loss += loss.item() * inputs.size(0)\n",
    "\n",
    "            # Calculate accuracy\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "    # Print validation statistics\n",
    "    val_loss /= len(val_loader.dataset)\n",
    "    val_accuracy = correct / total\n",
    "    print(f'Validation - Epoch [{epoch + 1}/{num_epochs}], Loss: {val_loss:.4f}, Accuracy: {val_accuracy:.4f}')\n",
    "\n",
    "    # Save the model if validation loss decreases\n",
    "    if val_loss < best_val_loss:\n",
    "        best_val_loss = val_loss\n",
    "        torch.save(model.state_dict(), '../models/' + f'{model_name}_font_classifier.pth')\n",
    "        print(f'Model saved as {model_name}_font_classifier.pth')\n",
    "        \n",
    "print('Finished Training')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-18T15:35:37.469484Z",
     "start_time": "2024-03-18T15:35:23.939329Z"
    }
   },
   "id": "2fb4051fe48bcb0f",
   "execution_count": 15
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Load the model\n",
    "model_path = '../models/' + f'{model_name}_font_classifier.pth'\n",
    "model = models.__dict__[model_name](weights=None)\n",
    "num_ftrs = model.fc.in_features\n",
    "model.fc = torch.nn.Linear(num_ftrs, len(class_names))\n",
    "model.load_state_dict(torch.load(model_path))\n",
    "model = model.to(device)\n",
    "print(f'Model loaded from {model_path}')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-18T15:35:37.471483Z",
     "start_time": "2024-03-18T15:35:37.471483Z"
    }
   },
   "id": "2d59abb3cc4d4ab1",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "Evaluate the model"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "c4fb0a8cc4c7aaaf"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Set the model to evaluation mode\n",
    "model.eval()\n",
    "\n",
    "# Initialize lists for true labels and predicted labels\n",
    "true_labels = []\n",
    "predicted_labels = []\n",
    "\n",
    "# Disable gradient computation for evaluation\n",
    "with torch.no_grad():\n",
    "    for images, labels in test_loader:\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        # Perform inference\n",
    "        outputs = model(images)\n",
    "        \n",
    "        # Compute predicted labels\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        \n",
    "        # Append true and predicted labels to lists\n",
    "        true_labels.extend(labels.cpu().numpy())\n",
    "        predicted_labels.extend(predicted.cpu().numpy())\n",
    "\n",
    "# Convert lists to numpy arrays\n",
    "true_labels = np.array(true_labels)\n",
    "predicted_labels = np.array(predicted_labels)\n",
    "\n",
    "# Compute accuracy\n",
    "accuracy = accuracy_score(true_labels, predicted_labels)\n",
    "print('Accuracy: {:.2f}%'.format(100 * accuracy))\n",
    "\n",
    "# Compute precision\n",
    "precision = precision_score(true_labels, predicted_labels, average='weighted')\n",
    "print('Precision: {:.2f}'.format(precision))\n",
    "\n",
    "# Compute recall\n",
    "recall = recall_score(true_labels, predicted_labels, average='weighted')\n",
    "print('Recall: {:.2f}'.format(recall))\n",
    "\n",
    "# Compute F1-score\n",
    "f1 = f1_score(true_labels, predicted_labels, average='weighted')\n",
    "print('F1-score: {:.2f}'.format(f1))\n",
    "\n",
    "# Compute confusion matrix\n",
    "conf_matrix = confusion_matrix(true_labels, predicted_labels)\n",
    "print(f'Confusion Matrix:')\n",
    "sns.heatmap(conf_matrix, annot=True, cmap='Blues', fmt='g', cbar=False, xticklabels=class_names, yticklabels=class_names)\n",
    "plt.title('Confusion Matrix')\n",
    "plt.xlabel('Predicted Label')\n",
    "plt.ylabel('True Label')\n",
    "plt.show()\n",
    "\n",
    "# Compute the ROC curve\n",
    "# Binarize the true labels\n",
    "true_labels_binarized = label_binarize(true_labels, classes=range(len(class_names)))\n",
    "\n",
    "# Binarize the predicted labels\n",
    "predicted_labels_binarized = label_binarize(predicted_labels, classes=range(len(class_names)))\n",
    "\n",
    "# Compute the ROC curve\n",
    "fpr = dict()\n",
    "tpr = dict()\n",
    "roc_auc = dict()\n",
    "for i in range(len(class_names)):\n",
    "    fpr[i], tpr[i], _ = roc_curve(true_labels_binarized[:, i], predicted_labels_binarized[:, i])\n",
    "    roc_auc[i] = auc(fpr[i], tpr[i])\n",
    "    \n",
    "# Plot the ROC curve\n",
    "plt.figure()\n",
    "for i in range(len(class_names)):\n",
    "    plt.plot(fpr[i], tpr[i], lw=2, label=f'ROC curve for class {class_names[i]} (area = {roc_auc[i]:0.2f})')\n",
    "plt.plot([0, 1], [0, 1], 'k--', lw=2)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-18T15:35:37.472483Z",
     "start_time": "2024-03-18T15:35:37.472483Z"
    }
   },
   "id": "6c7b4767f613c314",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "c4d8c6f85ef0d72c"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
